# -*- coding: utf-8 -*-
"""Scraper Regione Puglia v1.1 (Intelligente)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HavpNr1u1goy1cf-BAu-DJY62Mwpnpna
"""

# -*- coding: utf-8 -*-

# --- Scraper per "Bonus Facile" - Versione 1.1 (Regione Puglia Intelligente) ---
# Obiettivo: Estrarre i dettagli (ISEE, età) dalle pagine dei bandi della Regione Puglia.
# Correzione: Affinato il filtro semantico per escludere con maggiore precisione
# i concorsi pubblici e gli avvisi di selezione.
#
# Per eseguire questo script, assicurati di avere le librerie necessarie:
# py -m pip install selenium chromedriver-autoinstaller requests beautifulsoup4 psycopg2-binary python-dotenv lxml

import os
import requests
from bs4 import BeautifulSoup
import psycopg2
from urllib.parse import urljoin
from dotenv import load_dotenv
import hashlib
import time
import random
import re

# Importazioni per Selenium
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
import chromedriver_autoinstaller

# Carica le variabili d'ambiente da un file .env
load_dotenv()

# --- CONFIGURAZIONE ---
DATABASE_URL = os.getenv("DATABASE_URL")

REGIONE_PUGLIA_URL = "https://www.regione.puglia.it/bandi-e-avvisi"
REGIONE_PUGLIA_BASE_URL = "https://www.regione.puglia.it"
ID_FONTE = "reg_puglia_principale"

# --- MODIFICA CHIAVE v1.1: Filtro Semantico potenziato ---
TITLE_EXCLUSION_KEYWORDS = [
    'concorso pubblico', 'rettifica graduatoria', 'manifestazione di interesse',
    'affidamento di incarico', 'esiti attività', 'nomina commissione',
    'mobilità volontaria', 'elenco ammessi', 'selezione pubblica',
    'cessione graduatoria', 'esperti esterni'
]


def connect_to_db():
    """
    Crea e restituisce una connessione al database PostgreSQL.
    """
    try:
        conn = psycopg2.connect(DATABASE_URL)
        return conn
    except psycopg2.OperationalError as e:
        print(f"Errore: Impossibile connettersi al database.")
        return None

def extract_details_from_page(page_url):
    """
    Visita la pagina di un bando e tenta di estrarre ISEE, età e scadenza.
    """
    print(f"      -> Visitando la pagina per estrarre dettagli...")
    details = {"isee_max": None, "eta_min": None, "eta_max": None}
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(page_url, headers=headers, timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'lxml')

        page_text = soup.get_text().lower()

        # Estrazione ISEE
        isee_match = re.search(r'isee (?:non superiore a|di|fino a|massimo di|pari o inferiore a) ([\d\.,]+)', page_text)
        if isee_match:
            isee_str = isee_match.group(1).replace('.', '').replace(',', '.')
            details["isee_max"] = float(isee_str)
            print(f"         -> Trovato ISEE massimo: {details['isee_max']}")

        # Estrazione Età
        eta_match = re.search(r'età compresa tra ([\d]+) e ([\d]+) anni', page_text)
        if eta_match:
            details["eta_min"] = int(eta_match.group(1))
            details["eta_max"] = int(eta_match.group(2))
            print(f"         -> Trovato range di età: {details['eta_min']} - {details['eta_max']}")
        else:
            eta_max_match = re.search(r'(?:fino a|non superiore a|minore di) ([\d]+) anni', page_text)
            if eta_max_match:
                details["eta_max"] = int(eta_max_match.group(1))
                print(f"         -> Trovata età massima: {details['eta_max']}")

        return details

    except Exception as e:
        print(f"         -> Errore durante l'estrazione dei dettagli: {e}")
        return details

def scrape_regione_puglia():
    """
    Funzione principale che esegue lo scraping e l'inserimento dei dati.
    """
    print("--- Avvio scraper per Regione Puglia (Intelligente v1.1) ---")
    print("Strategia: Selenium per lista + Requests per dettagli.")

    print("1. Avvio del browser virtuale...")
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")

    chromedriver_autoinstaller.install()
    driver = None

    soup = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        print(f"2. Scaricamento della pagina: {REGIONE_PUGLIA_URL}")
        driver.get(REGIONE_PUGLIA_URL)

        print("   -> Attesa caricamento dinamico dei bandi...")
        wait = WebDriverWait(driver, 20)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.row.news-list-item")))

        html_content = driver.page_source
        soup = BeautifulSoup(html_content, 'lxml')
        print(f"   -> Pagina scaricata e analizzata con successo.")

    except TimeoutException:
        print("   -> ERRORE: Caricamento della pagina scaduto. Nessun bando trovato.")
        if driver: driver.quit()
        return
    except Exception as e:
        print(f"   -> ERRORE durante l'esecuzione di Selenium: {e}")
        if driver: driver.quit()
        return
    finally:
        if driver:
            driver.quit()
            print("   -> Browser virtuale chiuso.")

    candidate_bandi = soup.select('div.row.news-list-item')
    print(f"3. Trovati {len(candidate_bandi)} bandi candidati nella pagina.")

    if not candidate_bandi:
        return

    print("4. Inizio filtraggio e inserimento nel database...")

    conn = connect_to_db()
    if not conn:
        return

    cursor = conn.cursor()

    bandi_inseriti_totali = 0
    bandi_esistenti_totali = 0

    for bando_html in candidate_bandi:
        try:
            link_tag = bando_html.select_one('h2 a[href]')
            if not link_tag:
                continue

            titolo = link_tag.get_text(strip=True)

            titolo_lower = titolo.lower()
            if any(keyword in titolo_lower for keyword in TITLE_EXCLUSION_KEYWORDS):
                print(f"   -> SCARTATO (titolo non pertinente): '{titolo}'")
                continue

            link_relativo = link_tag['href']
            link_ufficiale = urljoin(REGIONE_PUGLIA_BASE_URL, link_relativo)

            # Estrai i dettagli dalla pagina del bando
            details = extract_details_from_page(link_ufficiale)

            stato_tag = bando_html.select_one('span.badge')
            stato = stato_tag.get_text(strip=True) if stato_tag else "Aperto"
            stato_standard = "Chiuso" if "chius" in stato.lower() else "Aperto"

            print(f"   -> PERTINENTE. Analizzando: '{titolo}' (Stato: {stato})")

            hash_id = hashlib.sha1(link_ufficiale.encode()).hexdigest()[:10]
            id_bando = f"reg_puglia_{hash_id}"

            bando_data = {
                "id_bando": id_bando, "titolo": titolo, "ente_erogatore": "Regione Puglia",
                "categoria": "Altro", "descrizione_breve": titolo, "link_ufficiale": link_ufficiale,
                "data_pubblicazione": None, "stato": stato_standard,
                "livello": "Regionale", "regione": "Puglia", "id_fonte": ID_FONTE,
                "isee_max": details["isee_max"],
                "eta_min": details["eta_min"],
                "eta_max": details["eta_max"],
            }

            insert_query = (
                "INSERT INTO bandi (id_bando, titolo, ente_erogatore, categoria, descrizione_breve, link_ufficiale, data_pubblicazione, stato, livello, regione, id_fonte, isee_max, eta_min, eta_max, data_ultimo_check) "
                "VALUES (%(id_bando)s, %(titolo)s, %(ente_erogatore)s, %(categoria)s, %(descrizione_breve)s, %(link_ufficiale)s, %(data_pubblicazione)s, %(stato)s, %(livello)s, %(regione)s, %(id_fonte)s, %(isee_max)s, %(eta_min)s, %(eta_max)s, NOW()) "
                "ON CONFLICT (id_bando) DO UPDATE SET "
                "titolo = EXCLUDED.titolo, stato = EXCLUDED.stato, isee_max = EXCLUDED.isee_max, eta_min = EXCLUDED.eta_min, eta_max = EXCLUDED.eta_max, data_ultimo_check = NOW();"
            )

            cursor.execute(insert_query, bando_data)

            if cursor.rowcount > 0:
                print(f"      -> Inserito nel database.")
                bandi_inseriti_totali += 1
            else:
                print(f"      -> Già esistente nel database.")
                bandi_esistenti_totali += 1

        except Exception as e:
            print(f"   -> ERRORE durante l'elaborazione di un bando: {e}")

        time.sleep(random.randint(1, 2))

    conn.commit()
    cursor.close()
    conn.close()

    print("\n--- Scraper per Regione Puglia (Intelligente) completato ---")
    print(f"Bandi inseriti o aggiornati: {bandi_inseriti_totali}")
    print(f"Bandi già esistenti e non modificati: {bandi_esistenti_totali}")


if __name__ == "__main__":
    scrape_regione_puglia()